{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "__FILE_DIR_PATH = os.path.dirname(__vsc_ipynb_file__) \\\n",
    "    if __IPYTHON__ \\\n",
    "    else os.path.dirname(__file__)\n",
    "    \n",
    "WORKSPACE_HOME = __FILE_DIR_PATH.replace(\n",
    "    f\"/{os.path.basename(__FILE_DIR_PATH)}\", \"\")\n",
    "WORKSPACE_HOME = WORKSPACE_HOME.replace(\"/trunk\", \"\")\n",
    "DATASET_DIR_HOME = f\"{WORKSPACE_HOME}/data/colley\"\n",
    "\n",
    "print(WORKSPACE_HOME)\n",
    "sys.path.append(WORKSPACE_HOME)\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from core import *\n",
    "from ipirec import *\n",
    "from colley import *\n",
    "\n",
    "# plt.rcParams[\"font.family\"] = \"AppleGothic\"\n",
    "plt.rcParams[\"font.family\"] = \"NanumGothic\"\n",
    "mpl.rcParams[\"axes.unicode_minus\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPT & ALLOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_FOLD_SET_ID = 2\n",
    "top_n_conditions = [n for n in range(3, 37, 2)]\n",
    "\n",
    "_TEST_SET_FILES_LIST = [\n",
    "    str.format(\n",
    "        \"{0}/test_{1}_{2}_list.csv\",\n",
    "        DATASET_DIR_HOME,\n",
    "        _FOLD_SET_ID,\n",
    "        DecisionType.to_str(d),\n",
    "    )\n",
    "    for d in [\n",
    "        DecisionType.E_LIKE,\n",
    "        DecisionType.E_PURCHASE,\n",
    "    ]\n",
    "]\n",
    "\n",
    "dataset = ColleyFilteredDataSet(dataset_dir_path=DATASET_DIR_HOME)\n",
    "dataset._load_metadata_()\n",
    "for decision_type in DecisionType:\n",
    "    dataset.append_decisions(\n",
    "        file_path=str.format(\n",
    "            \"{0}/train_{1}_{2}_list.csv\",\n",
    "            DATASET_DIR_HOME,\n",
    "            _FOLD_SET_ID,\n",
    "            DecisionType.to_str(decision_type),\n",
    "        ),\n",
    "        decision_type=decision_type,\n",
    "    )\n",
    "dataset.__id_index_mapping__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user: UserEntity = dataset.user_dict[692466]\n",
    "user.set_of_interest_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_tags = 5\n",
    "\n",
    "model_params = CorrelationModel.create_models_parameters(\n",
    "    top_n_tags=top_n_tags,\n",
    "    co_occur_items_threshold=4,\n",
    ")\n",
    "model = CorrelationModel(\n",
    "    dataset=dataset,\n",
    "    model_params=model_params,\n",
    ")\n",
    "model.analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.append_interest_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frob_norm = 1.0\n",
    "score_iters = 10\n",
    "weight_iters = 5\n",
    "\n",
    "estimator_params = AdjustedBiasedCorrelationEstimator.create_models_parameters(\n",
    "    score_iterations=score_iters,\n",
    "    score_learning_rate=10 ** -2,\n",
    "    score_generalization=10 ** -4,\n",
    "    weight_iterations=weight_iters,\n",
    "    weight_learning_rate=10 ** -3,\n",
    "    weight_generalization=1.0,\n",
    "    frob_norm=frob_norm,\n",
    "    default_voting=0.0,\n",
    ")\n",
    "estimator = AdjustedBiasedCorrelationEstimator(\n",
    "    model=model,\n",
    "    model_params=estimator_params,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for decision_type in DecisionType:\n",
    "    for _ in tqdm(\n",
    "        iterable=range(score_iters),\n",
    "        desc=f\"{DecisionType.to_str(decision_type)}\",\n",
    "        total=score_iters,\n",
    "    ):\n",
    "        _L = estimator._adjust_tags_corr_(\n",
    "            decision_type=decision_type,\n",
    "        )\n",
    "        print(f\"{_L}\")\n",
    "        # estimator._personalization_(\n",
    "        #     target_decision=decision_type,\n",
    "        # )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_uidx = estimator.user_id_to_idx.get(692466, -1)\n",
    "if _uidx != -1:\n",
    "    print(estimator.arr_users_tags_map[_uidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user: UserEntity = dataset.user_dict[692466]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_iidx = estimator.item_id_to_idx.get(472, -1)\n",
    "if _iidx != -1:\n",
    "    print(estimator.arr_items_tags_map[_iidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_log_list = list()\n",
    "_ITER = 0\n",
    "while True:\n",
    "    _ITER += 1\n",
    "    estimator.__append_biases__()\n",
    "    _L = estimator._adjust_tags_corr_(DecisionType.E_VIEW)\n",
    "    _S = np.std(estimator.arr_tags_score)\n",
    "    _W = np.std(estimator.arr_user_idx_to_weights)\n",
    "    print(\n",
    "        str.format(\n",
    "            \"[{0} S] L: {1}\\nS: {2}\\nW: {3}\",\n",
    "                _ITER,\n",
    "                _L,\n",
    "                _S,\n",
    "                _W,\n",
    "                )\n",
    "        )\n",
    "    # __L = _L +(( _S + _W)**(2**-1))\n",
    "    __L = _L +(_W**(2**-1))\n",
    "    print(__L)\n",
    "    _L = estimator._personalization_(DecisionType.E_VIEW)\n",
    "    _S = np.std(estimator.arr_tags_score)\n",
    "    _W = np.std(estimator.arr_user_idx_to_weights)\n",
    "    # _S = np.sum(np.abs(estimator.arr_tags_score))\n",
    "    # _W = np.sum(np.abs(estimator.arr_user_idx_to_weights))\n",
    "    print(\n",
    "        str.format(\n",
    "            \"[{0} W] L: {1}\\nS: {2}\\nW: {3}\",\n",
    "                _ITER,\n",
    "                _L,\n",
    "                _S,\n",
    "                _W,\n",
    "                )\n",
    "        )\n",
    "    # __L = _L +(( _S + _W)**(2**-1))\n",
    "    __L = _L +(_W**(2**-1))\n",
    "    print(__L)\n",
    "    loss_log_list.append(_L)\n",
    "    _min = min(loss_log_list)\n",
    "    if _min < _L:\n",
    "        _estimator: AdjustedBiasedCorrelationEstimator = copy.deepcopy(estimator)\n",
    "        break\n",
    "    \n",
    "inst = BaseAction(user_id=692466, item_id=472)\n",
    "inst = estimator._estimate_(inst)\n",
    "inst.estimated_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = BaseAction(user_id=692466, item_id=472)\n",
    "inst = estimator._estimate_(inst)\n",
    "inst.estimated_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ITER = 100\n",
    "# 21881.16485981459\n",
    "# 22906.855353528248 \n",
    "# [P -> S] 22847.84812020912 >> 25977.561489833748 >> 25564.655994604418\n",
    "decision_type = DecisionType.E_VIEW\n",
    "__E = list()\n",
    "for _ in tqdm(\n",
    "        iterable=range(_ITER),\n",
    "        desc=f\"{DecisionType.to_str(decision_type)}\",\n",
    "        total=_ITER,\n",
    "    ):\n",
    "        _L = estimator._adjust_tags_corr_(\n",
    "            decision_type=decision_type,\n",
    "        )\n",
    "        print(f\"{_L}\")\n",
    "        __E.append(_L)\n",
    "        if min(__E) < _L:\n",
    "            __E.clear()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ITER = 100\n",
    "# 7841.645698883881 >> 7956.079589877575\n",
    "# 8582.921496806883\n",
    "decision_type = DecisionType.E_LIKE\n",
    "__E = list()\n",
    "for _ in tqdm(\n",
    "        iterable=range(_ITER),\n",
    "        desc=f\"{DecisionType.to_str(decision_type)}\",\n",
    "        total=_ITER,\n",
    "    ):\n",
    "        _L = estimator._adjust_tags_corr_(\n",
    "            decision_type=decision_type,\n",
    "        )\n",
    "        print(f\"{_L}\")\n",
    "        __E.append(_L)\n",
    "        if min(__E) < _L:\n",
    "            __E.clear()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ITER = 100\n",
    "## 8901.497879940547\n",
    "# 8959.261042943654 >> 9056.971447119242\n",
    "# 9147.675861340429\n",
    "# [P->S] 8965.367465171059 >> 9147.313206731318\n",
    "# 9209.555742799665\n",
    "__E = list()\n",
    "decision_type = DecisionType.E_PURCHASE\n",
    "for _ in tqdm(\n",
    "        iterable=range(_ITER),\n",
    "        desc=f\"{DecisionType.to_str(decision_type)}\",\n",
    "        total=_ITER,\n",
    "    ):\n",
    "        if (__IPYTHON__) and (_ % 5 == 0):\n",
    "            clear_output(wait=True)\n",
    "        _L = estimator._adjust_tags_corr_(\n",
    "            decision_type=decision_type,\n",
    "        )\n",
    "        print(f\"{_L}\")\n",
    "        __E.append(_L)\n",
    "        if min(__E) < _L:\n",
    "            __E.clear()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = ScoreBasedRecommender(\n",
    "    estimator=estimator,\n",
    ")\n",
    "recommender.prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "recommender = ELABasedRecommender(\n",
    "    estimator=estimator,\n",
    ")\n",
    "recommender.prediction()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAL - Recommended items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = IRMetricsEvaluator(\n",
    "    recommender=recommender,\n",
    "    file_path=_TEST_SET_FILES_LIST[0],\n",
    ")\n",
    "evaluator.top_n_eval(\n",
    "    top_n_conditions=top_n_conditions,\n",
    ")\n",
    "df: DataFrame = evaluator.evlautions_summary_df()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = IRMetricsEvaluator(\n",
    "    recommender=recommender,\n",
    "    file_path=_TEST_SET_FILES_LIST[1],\n",
    ")\n",
    "evaluator.top_n_eval(\n",
    "    top_n_conditions=top_n_conditions,\n",
    ")\n",
    "df: DataFrame = evaluator.evlautions_summary_df()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAND >> W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_count = estimator.tags_count\n",
    "users_count = estimator.users_count\n",
    "\n",
    "_RAND_W: np.ndarray = np.random.rand(users_count, tags_count, tags_count)\n",
    "print(_RAND_W)\n",
    "estimator.arr_user_idx_to_weights = _RAND_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.model.arr_tags_score = np.tanh(estimator.arr_tags_score)\n",
    "estimator.arr_user_idx_to_weights = np.tanh(estimator.arr_user_idx_to_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_S: np.ndarray = copy.deepcopy(estimator.arr_tags_score)\n",
    "_W: np.ndarray = copy.deepcopy(estimator.arr_user_idx_to_weights)\n",
    "\n",
    "# _S = np.tanh(_S)\n",
    "_S\n",
    "# model.arr_tags_score = _S\n",
    "# estimator.model.arr_tags_score = _S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _W = np.tanh(_W)\n",
    "_W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IO] np.ndarray -- S, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S, W >> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_str = DirectoryPathValidator.current_datetime_str()\n",
    "\n",
    "file_path = str.format(\n",
    "    \"{0}/resources/IPIRec/{1}_S_{2}.npy\",\n",
    "    WORKSPACE_HOME,\n",
    "    _FOLD_SET_ID,\n",
    "    dt_str,\n",
    ")\n",
    "__dir_path = os.path.dirname(file_path)\n",
    "if not os.path.exists(__dir_path):\n",
    "    DirectoryPathValidator.mkdir(__dir_path)\n",
    "\n",
    "with open(file=file_path, mode=\"wb\") as fout:\n",
    "    np.save(fout, estimator.model.arr_tags_score)\n",
    "    fout.close()\n",
    "\n",
    "file_path = str.format(\n",
    "    \"{0}/resources/IPIRec/{1}_W_{2}.npy\",\n",
    "    WORKSPACE_HOME,\n",
    "    _FOLD_SET_ID,\n",
    "    dt_str,\n",
    ")\n",
    "with open(file=file_path, mode=\"wb\") as fout:\n",
    "    np.save(fout, estimator.arr_user_idx_to_weights)\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> S, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = str.format(\n",
    "    \"{0}/resources/IPIRec/{1}_S.npy\",\n",
    "    WORKSPACE_HOME,\n",
    "    _FOLD_SET_ID,\n",
    ")\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError()\n",
    "_S: np.ndarray = np.load(\n",
    "    file=file_path,\n",
    ")\n",
    "file_path = str.format(\n",
    "    \"{0}/resources/IPIRec/{1}_W.npy\",\n",
    "    WORKSPACE_HOME,\n",
    "    _FOLD_SET_ID,\n",
    ")\n",
    "_W: np.ndarray = np.load(\n",
    "    file=file_path,\n",
    ")\n",
    "estimator.model.arr_tags_score = _S\n",
    "estimator.arr_user_idx_to_weights = _W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ITER = 100\n",
    "# 39934.18908918701\n",
    "# [P->V] 39940.724917418236 >> 39939.05102884622\n",
    "__E = list()\n",
    "for decision_type in [DecisionType.E_VIEW,]:\n",
    "    for _ in range(_ITER):\n",
    "        _L = estimator._personalization_(decision_type)\n",
    "        print(f\"[{_ + 1} | {_ITER}]: {_L}\")\n",
    "        __E.append(_L)\n",
    "        if min(__E) < _L:\n",
    "            __E.clear()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ITER = 100\n",
    "# 10070.10165995471\n",
    "# 10062.877589213442 >> 10069.284461862013\n",
    "# 10062.394683458622\n",
    "# local optima가 빈번함; -- objective function에 momentum 가해야할 듯함 (근데 그러려면 2차함수를 구해줘야함)\n",
    "__E = list()\n",
    "for decision_type in [DecisionType.E_LIKE,]:\n",
    "    for _ in range(_ITER):\n",
    "        _L = estimator._personalization_(decision_type)\n",
    "        __E.append(_L)\n",
    "        print(f\"[{_ + 1} | {_ITER}]: {_L}\")\n",
    "        if min(__E) < _L:\n",
    "            __E.clear()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ITER = 100\n",
    "## 9959.982525242347\n",
    "# 10004.336950298619 >> 10005.550312827972\n",
    "# [P->S] 10005.334460052087\n",
    "# 10002.76615999305\n",
    "# V와 L보다 local optima가 더 빈번하므로, 목적함수를 좀 더 완화하도록 구성할 필요있음\n",
    "__E = list()\n",
    "for decision_type in [DecisionType.E_PURCHASE,]:\n",
    "    for _ in range(_ITER):\n",
    "        _L = estimator._personalization_(decision_type)\n",
    "        __E.append(_L)\n",
    "        print(f\"[{_ + 1} | {_ITER}]: {_L}\")\n",
    "        if min(__E) < _L:\n",
    "            __E.clear()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obs. Corr(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tags_score: np.ndarray = copy.deepcopy(estimator.arr_tags_score)\n",
    "plt.title(label=\"Tags scores\", fontsize=8.0)\n",
    "\n",
    "_min = np.min(_tags_score)\n",
    "_max = np.max(_tags_score[_tags_score < 1.0])\n",
    "_tag_names_list = list(estimator.tags_dict.keys())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "plt.xlabel(xlabel=\"Source tags name\", fontsize=4.0)\n",
    "plt.ylabel(ylabel=\"Target tags name\", fontsize=4.0)\n",
    "plt.xticks(fontsize=2.0)\n",
    "plt.yticks(fontsize=2.0)\n",
    "ax = sns.heatmap(\n",
    "    data=_tags_score,\n",
    "    vmin=_min,\n",
    "    vmax=_max,\n",
    "    cmap=\"Grays\",\n",
    "    xticklabels=_tag_names_list,\n",
    "    yticklabels=_tag_names_list,\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# \"\"\"\n",
    "tags_count = estimator.tags_count\n",
    "for _ in range(tags_count):\n",
    "    _tags_score[_][_] = 0.0\n",
    "ax = sns.clustermap(\n",
    "    _tags_score,\n",
    "    vmin=_min,\n",
    "    vmax=_max,\n",
    "    cmap=\"Grays\",\n",
    "    xticklabels=_tag_names_list,\n",
    "    yticklabels=_tag_names_list,\n",
    "    ## defaults\n",
    "    # cbar_kws=dict(use_gridspec=False, location=\"top\"),\n",
    "    # cbar_pos=(0.02, 0.8, 0.05, 0.18),\n",
    "    cbar_kws=dict(use_gridspec=False, location=\"top\"),\n",
    "    cbar_pos=(0.03, 0.85, 0.1, 0.01),\n",
    "    ## (pos_x, pos_y, len_x, len_y)\n",
    ")\n",
    "ax.tick_params(axis=\"x\", labelsize=2.0)\n",
    "ax.tick_params(axis=\"y\", labelsize=2.0)\n",
    "# \"\"\"\n",
    "\n",
    "_fig_file_path = str.format(\n",
    "    \"{0}/trunk/obs/set{1}_cmap.svg\",\n",
    "    WORKSPACE_HOME,\n",
    "    _FOLD_SET_ID,\n",
    ")\n",
    "__fig_dir_path = os.path.dirname(_fig_file_path)\n",
    "if not os.path.exists(__fig_dir_path):\n",
    "    DirectoryPathValidator.mkdir(__fig_dir_path)\n",
    "\n",
    "ax.figure.savefig(_fig_file_path)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HIER_HEATMAP\n",
    "\n",
    "_users_dist: np.ndarray = copy.deepcopy(estimator.arr_user_idx_to_weights)\n",
    "user_id = 424169\n",
    "plt.title(label=f\"W(u) = {user_id}\", fontsize=8.0)\n",
    "\n",
    "uidx = estimator.user_id_to_idx[user_id]\n",
    "if estimator.user_id_to_idx.get(user_id, -1) == -1:\n",
    "    raise KeyError()\n",
    "\n",
    "__OBS_W: np.ndarray = _users_dist[uidx]\n",
    "_min = np.min(__OBS_W)\n",
    "_max = np.max(__OBS_W[__OBS_W < 1.0])\n",
    "_tag_names_list = list(estimator.tags_dict.keys())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "plt.xlabel(xlabel=\"Source tags name\", fontsize=4.0)\n",
    "plt.ylabel(ylabel=\"Target tags name\", fontsize=4.0)\n",
    "plt.xticks(fontsize=2.0)\n",
    "plt.yticks(fontsize=2.0)\n",
    "ax = sns.heatmap(\n",
    "    data=__OBS_W,\n",
    "    vmin=_min,\n",
    "    vmax=_max,\n",
    "    cmap=\"Grays\",\n",
    "    xticklabels=_tag_names_list,\n",
    "    yticklabels=_tag_names_list,\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# \"\"\"\n",
    "tags_count = estimator.tags_count\n",
    "for _ in range(tags_count):\n",
    "    __OBS_W[_][_] = 0.0\n",
    "ax = sns.clustermap(\n",
    "    __OBS_W,\n",
    "    vmin=_min,\n",
    "    vmax=_max,\n",
    "    cmap=\"Grays\",\n",
    "    xticklabels=_tag_names_list,\n",
    "    yticklabels=_tag_names_list,\n",
    "    ## defaults\n",
    "    # cbar_kws=dict(use_gridspec=False, location=\"top\"),\n",
    "    # cbar_pos=(0.02, 0.8, 0.05, 0.18),\n",
    "    cbar_kws=dict(use_gridspec=False, location=\"top\"),\n",
    "    cbar_pos=(0.03, 0.85, 0.1, 0.01),\n",
    "    ## (pos_x, pos_y, len_x, len_y)\n",
    ")\n",
    "ax.tick_params(axis=\"x\", labelsize=2.0)\n",
    "ax.tick_params(axis=\"y\", labelsize=2.0)\n",
    "# \"\"\"\n",
    "\n",
    "_fig_file_path = str.format(\n",
    "    \"{0}/trunk/obs/set{1}_W_u{2}_cmap.svg\",\n",
    "    WORKSPACE_HOME,\n",
    "    _FOLD_SET_ID,\n",
    "    user_id,\n",
    ")\n",
    "__fig_dir_path = os.path.dirname(_fig_file_path)\n",
    "if not os.path.exists(__fig_dir_path):\n",
    "    DirectoryPathValidator.mkdir(__fig_dir_path)\n",
    "\n",
    "ax.figure.savefig(_fig_file_path)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HEATMAP\n",
    "_users_dist: np.ndarray = copy.deepcopy(estimator.arr_user_idx_to_weights)\n",
    "user_id = 424169\n",
    "plt.title(label=f\"W(u) = {user_id}\", fontsize=8.0)\n",
    "\n",
    "uidx = estimator.user_id_to_idx[user_id]\n",
    "if estimator.user_id_to_idx.get(user_id, -1) == -1:\n",
    "    raise KeyError()\n",
    "\n",
    "__OBS_W: np.ndarray = _users_dist[uidx]\n",
    "_min = np.min(__OBS_W)\n",
    "_max = np.max(__OBS_W[__OBS_W < 1.0])\n",
    "_tag_names_list = list(estimator.tags_dict.keys())\n",
    "\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "tags_count = estimator.tags_count\n",
    "for _ in range(tags_count):\n",
    "    __OBS_W[_][_] = 0.0\n",
    "\n",
    "plt.xlabel(xlabel=\"Source tags name\", fontsize=4.0)\n",
    "plt.ylabel(ylabel=\"Target tags name\", fontsize=4.0)\n",
    "plt.xticks(fontsize=2.0)\n",
    "plt.yticks(fontsize=2.0)\n",
    "ax = sns.heatmap(\n",
    "    data=__OBS_W,\n",
    "    vmin=_min,\n",
    "    vmax=_max,\n",
    "    cmap=\"Grays\",\n",
    "    xticklabels=_tag_names_list,\n",
    "    yticklabels=_tag_names_list,\n",
    ")\n",
    "ax.tick_params(axis=\"x\", labelsize=2.0)\n",
    "ax.tick_params(axis=\"y\", labelsize=2.0)\n",
    "# \"\"\"\n",
    "\n",
    "_fig_file_path = str.format(\n",
    "    \"{0}/trunk/obs/set{1}_W_u{2}.svg\",\n",
    "    WORKSPACE_HOME,\n",
    "    _FOLD_SET_ID,\n",
    "    user_id,\n",
    ")\n",
    "__fig_dir_path = os.path.dirname(_fig_file_path)\n",
    "if not os.path.exists(__fig_dir_path):\n",
    "    DirectoryPathValidator.mkdir(__fig_dir_path)\n",
    "\n",
    "ax.figure.savefig(_fig_file_path)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S * W(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HIER_HEATMAP\n",
    "user_id = 424169\n",
    "\n",
    "_tags_score: np.ndarray = copy.deepcopy(estimator.arr_tags_score)\n",
    "_tag_names_list = list(estimator.tags_dict.keys())\n",
    "\n",
    "tags_count = estimator.tags_count\n",
    "plt.title(label=f\"S * W(u) = {user_id}\", fontsize=8.0)\n",
    "\n",
    "uidx = estimator.user_id_to_idx[user_id]\n",
    "if estimator.user_id_to_idx.get(user_id, -1) == -1:\n",
    "    raise KeyError()\n",
    "\n",
    "_users_dist: np.ndarray = copy.deepcopy(estimator.arr_user_idx_to_weights)\n",
    "__OBS_W: np.ndarray = _users_dist[uidx]\n",
    "\n",
    "for _ in range(tags_count):\n",
    "    _tags_score[_][_] = 0.0\n",
    "    __OBS_W[_][_] = 0.0\n",
    "\n",
    "_WS = _tags_score * __OBS_W\n",
    "_min = np.min(_WS)\n",
    "_max = np.max(_WS[_WS < 1.0])\n",
    "ax = sns.clustermap(\n",
    "    _WS,\n",
    "    vmin=_min,\n",
    "    vmax=_max,\n",
    "    cmap=\"Grays\",\n",
    "    xticklabels=_tag_names_list,\n",
    "    yticklabels=_tag_names_list,\n",
    "    ## defaults\n",
    "    # cbar_kws=dict(use_gridspec=False, location=\"top\"),\n",
    "    # cbar_pos=(0.02, 0.8, 0.05, 0.18),\n",
    "    cbar_kws=dict(use_gridspec=False, location=\"top\"),\n",
    "    cbar_pos=(0.03, 0.85, 0.1, 0.01),\n",
    "    ## (pos_x, pos_y, len_x, len_y)\n",
    ")\n",
    "ax.tick_params(axis=\"x\", labelsize=2.0)\n",
    "ax.tick_params(axis=\"y\", labelsize=2.0)\n",
    "# \"\"\"\n",
    "\n",
    "_fig_file_path = str.format(\n",
    "    \"{0}/trunk/obs/set{1}_WS_u{2}_cmap.svg\",\n",
    "    WORKSPACE_HOME,\n",
    "    _FOLD_SET_ID,\n",
    "    user_id,\n",
    ")\n",
    "__fig_dir_path = os.path.dirname(_fig_file_path)\n",
    "if not os.path.exists(__fig_dir_path):\n",
    "    DirectoryPathValidator.mkdir(__fig_dir_path)\n",
    "\n",
    "ax.figure.savefig(_fig_file_path)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## HEATMAP\n",
    "user_id = 424169\n",
    "_tags_score: np.ndarray = copy.deepcopy(estimator.arr_tags_score)\n",
    "plt.title(label=f\"W * S ({user_id})\", fontsize=8.0)\n",
    "\n",
    "_min = np.min(_tags_score)\n",
    "_max = np.max(_tags_score[_tags_score < 1.0])\n",
    "_tag_names_list = list(estimator.tags_dict.keys())\n",
    "\n",
    "tags_count = estimator.tags_count\n",
    "_users_dist: np.ndarray = copy.deepcopy(estimator.arr_user_idx_to_weights)\n",
    "\n",
    "uidx = estimator.user_id_to_idx[user_id]\n",
    "if estimator.user_id_to_idx.get(user_id, -1) == -1:\n",
    "    raise KeyError()\n",
    "\n",
    "__OBS_W: np.ndarray = _users_dist[uidx]\n",
    "_min = np.min(__OBS_W)\n",
    "_max = np.max(__OBS_W[__OBS_W < 1.0])\n",
    "_tag_names_list = list(estimator.tags_dict.keys())\n",
    "\n",
    "for _ in range(tags_count):\n",
    "    _tags_score[_][_] = 0.0\n",
    "    __OBS_W[_][_] = 0.0\n",
    "\n",
    "_WS = _tags_score * __OBS_W\n",
    "\n",
    "plt.xlabel(xlabel=\"Source tags name\", fontsize=4.0)\n",
    "plt.ylabel(ylabel=\"Target tags name\", fontsize=4.0)\n",
    "plt.xticks(fontsize=2.0)\n",
    "plt.yticks(fontsize=2.0)\n",
    "ax = sns.heatmap(\n",
    "    data=_WS,\n",
    "    vmin=_min,\n",
    "    vmax=_max,\n",
    "    cmap=\"Grays\",\n",
    "    xticklabels=_tag_names_list,\n",
    "    yticklabels=_tag_names_list,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "_fig_file_path = str.format(\n",
    "    \"{0}/trunk/obs/set{1}_WS_u{2}.svg\",\n",
    "    WORKSPACE_HOME,\n",
    "    _FOLD_SET_ID,\n",
    "    user_id,\n",
    ")\n",
    "__fig_dir_path = os.path.dirname(_fig_file_path)\n",
    "if not os.path.exists(__fig_dir_path):\n",
    "    DirectoryPathValidator.mkdir(__fig_dir_path)\n",
    "\n",
    "ax.figure.savefig(_fig_file_path)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAL - Tags scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_scores_evaluator = TagsScoreRMSEEvaluator(\n",
    "    recommender=recommender,\n",
    "    file_path=_TEST_SET_FILES_LIST[0],\n",
    ")\n",
    "\n",
    "tags_scores_evaluator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_scores_evaluator = TagsScoreRMSEEvaluator(\n",
    "    recommender=recommender,\n",
    "    file_path=_TEST_SET_FILES_LIST[1],\n",
    ")\n",
    "\n",
    "tags_scores_evaluator.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diff. of Tags Freq. - Rec. Items;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec_tags_freq import CosineItemsTagsFreqAddPenalty\n",
    "\n",
    "rec_tags_freq_dist = CosineItemsTagsFreqAddPenalty()\n",
    "evaluator = IRMetricsEvaluator(\n",
    "    recommender=recommender,\n",
    "    file_path=_TEST_SET_FILES_LIST[0],\n",
    ")\n",
    "avg_cos_dist = rec_tags_freq_dist.tags_freq_distance(\n",
    "    test_set=evaluator.TEST_SET_LIST,\n",
    "    recommender=recommender\n",
    ")\n",
    "print(f\"L: {avg_cos_dist}\")\n",
    "\n",
    "evaluator = IRMetricsEvaluator(\n",
    "    recommender=recommender,\n",
    "    file_path=_TEST_SET_FILES_LIST[1],\n",
    ")\n",
    "avg_cos_dist = rec_tags_freq_dist.tags_freq_distance(\n",
    "    test_set=evaluator.TEST_SET_LIST,\n",
    "    recommender=recommender\n",
    ")\n",
    "print(f\"P: {avg_cos_dist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone -- estimator;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dummy_estimator: AdjustedBiasedCorrelationEstimator = copy.deepcopy(estimator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
